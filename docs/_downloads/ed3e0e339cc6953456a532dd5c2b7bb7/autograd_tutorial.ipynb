{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python",
      "version": "3.5.0",
      "pygments_lexer": "ipython3",
      "file_extension": ".py"
    }
  },
  "cells": [
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "\nAutograd\n========\n\nAutograd\ub294 \uc790\ub3d9 \ubbf8\ubd84\uc744 \uc218\ud589\ud558\ub294 torch\uc758 \ud575\uc2ec \ud328\ud0a4\uc9c0\ub85c, \uc790\ub3d9 \ubbf8\ubd84\uc744 \uc704\ud574\n\ud14c\uc78e(tape) \uae30\ubc18 \uc2dc\uc2a4\ud15c\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\n\uc21c\uc804\ud30c(forward) \ub2e8\uacc4\uc5d0\uc11c autograd \ud14c\uc78e\uc740 \uc218\ud589\ud558\ub294 \ubaa8\ub4e0 \uc5f0\uc0b0\uc744 \uae30\uc5b5\ud569\ub2c8\ub2e4.\n\uadf8\ub9ac\uace0, \uc5ed\uc804\ud30c(backward) \ub2e8\uacc4\uc5d0\uc11c \uc5f0\uc0b0\ub4e4\uc744 \uc7ac\uc0dd(replay)\ud569\ub2c8\ub2e4.\n\n\uc774\ub825(history)\uc744 \ucd94\uc801(track)\ud558\ub294 Tensor\n---------------------------------------\n\nAutograd\uc5d0\uc11c ``requires_grad=True`` \ub85c \uc124\uc815\ub41c \uc5b4\ub5a4 \uc785\ub825 ``Tensor`` \uc758 \uc5f0\uc0b0\uc740\n\uae30\ub85d\ub429\ub2c8\ub2e4. \uc5ed\uc804\ud30c \ub2e8\uacc4 \uc5f0\uc0b0 \ud6c4\uc5d0, \uc774 \ubcc0\uc218\uc5d0 \ub300\ud55c \ubcc0\ud654\ub3c4(grdient)\ub294 ``.grad`` \uc5d0\n\ub204\uc801\ub429\ub2c8\ub2e4.\n\nAutograd \uad6c\ud604\uc5d0\uc11c \ub9e4\uc6b0 \uc911\uc694\ud55c \ud074\ub798\uc2a4\uac00 \ud558\ub098 \ub354 \uc788\ub294\ub370\uc694, \ubc14\ub85c ``Function`` \ud074\ub798\uc2a4\uc785\ub2c8\ub2e4.\n``Tensor`` \uacfc ``Function`` \uc740 \uc0c1\ud638 \uc5f0\uacb0\ub418\uc5b4 \uc788\uc73c\uba70,\n\ubaa8\ub4e0 \uc5f0\uc0b0 \uacfc\uc815\uc744 \ubd80\ud638\ud654(encode)\ud558\uc5ec \uc21c\ud658\ud558\uc9c0 \uc54a\uc740 \uadf8\ub798\ud504(acyclic graph)\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n\uac01 \ubcc0\uc218\ub294 ``.grad_fn`` \uc18d\uc131\uc744 \uac16\uace0 \uc788\ub294\ub370, \uc774\ub294 ``Tensor`` \uc744 \uc0dd\uc131\ud55c ``Function`` \uc744\n\ucc38\uc870\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. (\ub2e8, \uc0ac\uc6a9\uc790\uac00 \ub9cc\ub4e0 Tensor\ub294 \uc608\uc678\ub85c, \uc774 \ub54c ``grad_fn`` \uc740\n``None`` \uc785\ub2c8\ub2e4.)\n\n\ub3c4\ud568\uc218\ub97c \uacc4\uc0b0\ud558\uae30 \uc704\ud574\uc11c\ub294, ``Tensor`` \uc758 ``.backward()`` \ub97c \ud638\ucd9c\ud558\uba74 \ub429\ub2c8\ub2e4.\n``Tensor`` \uc774 \uc2a4\uce7c\ub77c(scalar)\uc778 \uacbd\uc6b0(\uc608. \ud558\ub098\uc758 \uc694\uc18c\ub9cc \uac16\ub294 \ub4f1)\uc5d0\ub294, ``backward`` \uc5d0\n\uc778\uc790\ub97c \uc815\ud574\uc904 \ud544\uc694\uac00 \uc5c6\uc2b5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc5ec\ub7ec \uac1c\uc758 \uc694\uc18c\ub97c \uac16\uace0 \uc788\uc744 \ub54c\ub294 tensor\uc758\n\ubaa8\uc591\uc744 ``gradient`` \uc758 \uc778\uc790\ub85c \uc9c0\uc815\ud560 \ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "tensor\ub97c \uc0dd\uc131\ud558\uace0 \uc5f0\uc0b0\uc744 \ucd94\uc801\ud558\uae30 \uc704\ud574 requires_grad=True\ub85c \uc124\uc815\ud569\ub2c8\ub2e4.\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\nprint(x)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(x.data)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(x.grad)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(x.grad_fn)  # we've created x ourselves"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "\ubcc0\uc218 x\uc5d0 \uc5f0\uc0b0\uc744 \uc218\ud589\ud569\ub2c8\ub2e4:\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "y = x + 2\nprint(y)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "y \ub294 \uc5f0\uc0b0\uc758 \uacb0\uacfc\ub85c \uc0dd\uc131\ub41c \uac83\uc774\ubbc0\ub85c, grad_fn \uc744 \uac16\uc2b5\ub2c8\ub2e4.print(y.grad_fn)\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "y\uc5d0 \ub2e4\ub978 \uc5f0\uc0b0\uc744 \uc218\ud589\ud569\ub2c8\ub2e4:\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = y * y * 3\nout = z.mean()\n\nprint(z, out)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "``.requires_grad_( ... )`` \ub294 \uae30\uc874 Tensor\uc758 ``requires_grad`` \uac12\uc744 In-place\ub85c\n\ubcc0\uacbd\ud569\ub2c8\ub2e4. \uc785\ub825\uac12\uc774 \uc9c0\uc815\ub418\uc9c0 \uc54a\uc73c\uba74 \uae30\ubcf8\uac12\uc740 ``True`` \uc785\ub2c8\ub2e4.\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a = torch.randn(2, 2)\na = ((a * 3) / (a - 1))\nprint(a.requires_grad)\na.requires_grad_(True)\nprint(a.requires_grad)\nb = (a * a).sum()\nprint(b.grad_fn)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "\ubcc0\ud654\ub3c4(Gradient)\n----------------\n\n\uc774\uc81c \uc5ed\uc804\ud30c(backprop)\ub97c \ud558\uace0 \ubcc0\ud654\ub3c4 d(out)/dx\ub97c \ucd9c\ub825\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out.backward()\nprint(x.grad)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "\uae30\ubcf8\uc801\uc73c\ub85c \ubcc0\ud654\ub3c4 \uc5f0\uc0b0\uc740 \uadf8\ub798\ud504 \uc0c1\uc758 \ubaa8\ub4e0 \ub0b4\ubd80 \ubc84\ud37c\ub97c \uc0c8\ub85c \uc4f0\uae30(flush) \ub54c\ubb38\uc5d0,\n\uadf8\ub798\ud504\uc758 \ud2b9\uc815 \ubd80\ubd84\uc5d0 \ub300\ud574\uc11c \uc5ed\uc804\ud30c \uc5f0\uc0b0\uc744 2\ubc88\ud558\uace0 \uc2f6\ub2e4\uba74, \uccab \uc5f0\uc0b0 \ub2e8\uacc4\uc5d0\uc11c\n``retain_variables = True`` \uac12\uc744 \ub118\uaca8\uc918\uc57c \ud569\ub2c8\ub2e4.\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\ny = x + 2\ny.backward(torch.ones(2, 2), retain_graph=True)\n# retain_variables flag\ub294 \ub0b4\ubd80 \ubc84\ud37c\uac00 \uc0ac\ub77c\uc9c0\ub294 \uac83\uc744 \ub9c9\uc544\uc90d\ub2c8\ub2e4.\nprint(x.grad)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z = y * y\nprint(z)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "\ubb34\uc791\uc704 \uac12\uc73c\ub85c \uc5ed\uc804\ud30c\ub97c \ud569\ub2c8\ub2e4.\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gradient = torch.randn(2, 2)\n\n# retain_variable \uc744 \uc9c0\uc815\ud558\uc9c0 \uc54a\uc558\ub2e4\uba74 \uc624\ub958\uac00 \ubc1c\uc0dd\ud560 \uac83\uc785\ub2c8\ub2e4.\ny.backward(gradient)\n\nprint(x.grad)"
      ],
      "cell_type": "code",
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "``with torch.no_grad():`` \ub85c \ucf54\ub4dc \ube14\ub7ed(Code Block)\uc744 \uac10\uc2f8\uc11c, autograd\uac00\nrequires_grad=True\uc778 Tensor\ub4e4\uc758 \uc5f0\uc0b0 \uae30\ub85d\uc744 \ucd94\uc801\ud558\ub294 \uac83\uc744 \uba48\ucd9c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(x.requires_grad)\nprint((x ** 2).requires_grad)\n\nwith torch.no_grad():\n\tprint((x ** 2).requires_grad)"
      ],
      "cell_type": "code",
      "execution_count": null
    }
  ],
  "nbformat_minor": 0,
  "nbformat": 4
}