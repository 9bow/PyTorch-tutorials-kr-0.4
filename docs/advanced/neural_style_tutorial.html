

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
    <link rel="canonical" href="http://tutorials.pytorch.kr/advanced/neural_style_tutorial.html" />
  <meta charset="utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>PyTorch를 이용한 신경망-변환(Neural-Transfer) &mdash; PyTorch Tutorials 0.4.0 documentation</title>

















    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />



    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />

    <link rel="stylesheet" href="../_static/css/pytorch_theme.css" type="text/css" />

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />



        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="PyTorch Tutorials 0.4.0 documentation" href="../index.html"/>
        <link rel="next" title="Creating extensions using numpy and scipy" href="numpy_extensions_tutorial.html"/>
        <link rel="prev" title="공간 변형기 네트워크(Spatial Transformer Networks) 튜토리얼" href="../intermediate/spatial_transformer_tutorial.html"/>


  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">


  <div class="wy-grid-for-nav">


    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">



            <a href="../index.html" class="icon icon-home"> PyTorch Tutorials




            <img src="../_static/pytorch-logo-dark.svg" class="logo" />

          </a>




              <div class="version">
                0.4.0
              </div>




<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">






              <p class="caption"><span class="caption-text">Beginner Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">PyTorch로 딥러닝하기: 60분만에 끝장내기</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html">PyTorch가 무엇인가요?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#id1">시작하기</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#tensors">Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#operations">연산(Operations)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#numpy-bridge">NumPy 변환(Bridge)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#torch-tensor-numpy">Torch Tensor를 NumPy 배열로 변환하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#numpy-torch-tensor">NumPy 배열을 Torch Tensor로 변환하기</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/blitz/autograd_tutorial.html">Autograd: 자동 미분</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/autograd_tutorial.html#tensor">Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/autograd_tutorial.html#gradient">변화도(Gradient)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html">신경망(Neural Networks)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html#id1">신경망 정의하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html#loss-function">손실 함수 (Loss Function)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html#backprop">역전파(Backprop)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html#id4">가중치 갱신</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html">분류기(Classifier) 학습하기</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#id1">데이터는 어떻게 하나요?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#id2">이미지 분류기 학습하기</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#cifar10">1. CIFAR10를 불러오고 정규화하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#convolution-neural-network">2. 합성곱 신경망(Convolution Neural Network) 정의하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#optimizer">3. 손실 함수와 Optimizer 정의하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#id3">4. 신경망 학습하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#id4">5. 시험용 데이터로 신경망 검사하기</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#gpu">GPU에서 학습하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#id5">여러개의 GPU에서 학습하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#id6">이제 뭘 해볼까요?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html">Optional: Data Parallelism</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#imports-and-parameters">Imports and parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#dummy-dataset">Dummy DataSet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#simple-model">Simple Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#create-model-and-dataparallel">Create Model and DataParallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#run-the-model">Run the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#results">Results</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#gpus">2 GPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#id1">3 GPUs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#id2">8 GPUs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/data_parallel_tutorial.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/former_torchies_tutorial.html">Torch 사용자를 위한 PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html">Tensor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#in-place-out-of-place">In-place / Out-of-place</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#zero-indexing">0-인덱스(Zero Indexing)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#camel-case">카멜표기법(Camel Case) 없음</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#numpy-bridge">NumPy 변환(Bridge)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#torch-tensor-numpy">Torch Tensor를 NumPy 배열로 변환하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#numpy-torch-tensor">NumPy 배열을 Torch Tensor로 변환하기</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/former_torchies/autograd_tutorial.html">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/autograd_tutorial.html#history-track-tensor">이력(history)을 추적(track)하는 Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/autograd_tutorial.html#gradient">변화도(Gradient)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/former_torchies/nn_tutorial.html">nn 패키지</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/nn_tutorial.html#convnet">예제1: 합성곱 신경망(ConvNet)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/nn_tutorial.html#hook">순방향/역방향 함수 훅(Hook)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/nn_tutorial.html#recurrent-nets">예제2: 순환 신경망(Recurrent Nets)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/former_torchies/parallelism_tutorial.html">멀티-GPU 예제</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/parallelism_tutorial.html#dataparallel">DataParallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/parallelism_tutorial.html#cpu-gpu">모델의 일부는 CPU, 일부는 GPU에서</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">예제로 배우는 PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/pytorch_with_examples.html#tensor">Tensor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#numpy">준비 운동: NumPy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-tensor">PyTorch: Tensor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/pytorch_with_examples.html#autograd">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-tensor-autograd">PyTorch: Tensor와 autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-autograd">PyTorch: 새 autograd 함수 정의하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#tensorflow-static-graph">TensorFlow: 정적 그래프(Static Graph)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/pytorch_with_examples.html#nn"><cite>nn</cite> 모듈</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-nn">PyTorch: nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-optim">PyTorch: optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#id3">PyTorch: 사용자 정의 nn 모듈</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-control-flow-weight-sharing">PyTorch: 제어 흐름(Control Flow) + 가중치 공유(Weight Sharing)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/pytorch_with_examples.html#examples-download">예제 코드</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#id5">Tensor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_tensor/two_layer_net_numpy.html">준비 운동: NumPy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_tensor/two_layer_net_tensor.html">PyTorch: Tensor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#id6">Autograd</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_autograd/two_layer_net_autograd.html">PyTorch: Tensor와 autograd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_autograd/two_layer_net_custom_function.html">PyTorch: 새 autograd 함수 정의하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_autograd/tf_two_layer_net.html">TensorFlow: 정적 그래프(Static Graph)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#id7"><cite>nn</cite> 모듈</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_nn/two_layer_net_nn.html">PyTorch: nn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_nn/two_layer_net_optim.html">PyTorch: optim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_nn/two_layer_net_module.html">PyTorch: 사용자 정의 nn 모듈</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_nn/dynamic_net.html">PyTorch: 제어 흐름(Control Flow) + 가중치 공유(Weight Sharing)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">전이학습(Transfer Learning) 튜토리얼</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#id2">데이터 불러오기</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#id4">일부 이미지 시각화하기</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#id5">모델 학습하기</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#id6">모델 예측값 시각화하기</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#finetuning">합성곱 신경망 미세조정(Finetuning)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#id7">학습 및 평가하기</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#id8">고정 특정 추출기로써의 합성곱 신경망</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#id9">학습 및 평가하기</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/data_loading_tutorial.html">Data Loading and Processing Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/data_loading_tutorial.html#dataset-class">Dataset class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/data_loading_tutorial.html#transforms">Transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/data_loading_tutorial.html#compose-transforms">Compose transforms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/data_loading_tutorial.html#iterating-through-the-dataset">Iterating through the dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/data_loading_tutorial.html#afterword-torchvision">Afterword: torchvision</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html">PyTorch 소개</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#torch-tensor">Torch의 텐서(Tensor) 라이브러리 소개</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#id1">텐서 생성하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#id2">텐서로 작업하기</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#id3">텐서 재구성</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#computation-graph-automatic-differentiation">연산 그래프(Computation Graph)와 자동 미분(Automatic Differentiation)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html">PyTorch를 이용한 딥러닝</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#affine-maps">딥러닝 블록 구축 : 아핀 맵(affine maps), 비선형성, 객체</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#id1">아핀 맵</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#id2">비선형성</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#softmax">Softmax 및 확률</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#objective-functions">목적 함수(Objective Functions)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#id3">최적화와 학습</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#id4">Pytorch 에서 네트워크 구성요소 생성하기</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#bag-of-words">예제: 논리 회귀 Bag-of-Words 분류기</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html">Word Embeddings: Encoding Lexical Semantics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html#getting-dense-word-embeddings">Getting Dense Word Embeddings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html#word-embeddings-in-pytorch">Word Embeddings in Pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html#an-example-n-gram-language-modeling">An Example: N-Gram Language Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html#exercise-computing-word-embeddings-continuous-bag-of-words">Exercise: Computing Word Embeddings: Continuous Bag-of-Words</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/sequence_models_tutorial.html">Sequence Models and Long-Short Term Memory Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/sequence_models_tutorial.html#lstm-s-in-pytorch">LSTM’s in Pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/sequence_models_tutorial.html#example-an-lstm-for-part-of-speech-tagging">Example: An LSTM for Part-of-Speech Tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/sequence_models_tutorial.html#exercise-augmenting-the-lstm-part-of-speech-tagger-with-character-level-features">Exercise: Augmenting the LSTM part-of-speech tagger with character-level features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html">Advanced: Making Dynamic Decisions and the Bi-LSTM CRF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html#dynamic-versus-static-deep-learning-toolkits">Dynamic versus Static Deep Learning Toolkits</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html#bi-lstm-conditional-random-field-discussion">Bi-LSTM Conditional Random Field Discussion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html#exercise-a-new-loss-function-for-discriminative-tagging">Exercise: A new loss function for discriminative tagging</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Intermediate Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">문자-단위 RNN으로 이름 분류하기</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#id2">데이터 준비하기</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#tensor">이름을 Tensor 로 변경</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#id3">네트워크 생성</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#id4">학습</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#id5">학습 준비</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#id6">네트워크 학습</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#id7">결과 도식화</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#id8">결과 평가</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#id9">사용자 입력으로 실행</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#id10">연습</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">문자-단위 RNN으로 이름 생성하기</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#id2">데이터 준비하기</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#id4">네트워크 생성</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#id5">학습</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#id6">학습 준비</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#id7">네트워크 학습</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#id8">손실 도식화</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#id9">네트워크 샘플링</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">Sequence to Sequence 네트워크와 Attention을 이용한 번역</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id2">데이터 파일 로딩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#seq2seq">Seq2Seq 모델</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id4">인코더</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id5">디코더</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id6">간단한 디코더</a></li>
<li class="toctree-l4"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id7">어텐션 디코더</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id8">학습</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id9">학습 데이터 준비</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id10">모델 학습</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id11">결과 도식화</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id12">평가</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id13">학습과 평가</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id14">어텐션 시각화</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#id15">연습</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">강화 학습 (DQN) 튜토리얼</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#replay-memory">재현 메모리(Replay Memory)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#id2">DQN 알고리즘</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#q">Q-네트워크</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#id3">입력 추출</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#id4">학습</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#id5">하이퍼 파라미터와 유틸리티</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#id8">학습 루프</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Pytorch로 분산 어플리케이션 개발하기</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#setup">Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#point-to-point-communication">지점간 통신(Point-to-Point Communication)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#collective-communication">집단 통신 (Collective Communication)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#distributed-training">분산 학습(Distributed Training)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/dist_tuto.html#our-own-ring-allreduce">Our Own Ring-Allreduce</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#advanced-topics">Advanced Topics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/dist_tuto.html#id2">통신 백엔드</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/dist_tuto.html#id3">초기화 방법</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">공간 변형기 네트워크(Spatial Transformer Networks) 튜토리얼</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#id2">데이터 로딩</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#id3">공간 변형 네트워크 설명</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#id4">모델 학습</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#stn">STN 결과 시각화</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Advanced Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">PyTorch를 이용한 신경망-변환(Neural-Transfer)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id2">소개</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">신경망 뭐라고?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">어떻게 동작합니까?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id5">그래서. 어떻게 동작하냐고요?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pytorch">PyTorch 구현</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id6">패키지들</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cuda">쿠다(CUDA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">이미지 읽기</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">이미지 표시하기</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">콘텐츠 로스</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id10">스타일 로스</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">뉴럴 네트워크 읽기</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id16">입력 이미지</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id17">경사 하강법</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="numpy_extensions_tutorial.html">Creating extensions using numpy and scipy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="numpy_extensions_tutorial.html#parameter-less-example">Parameter-less example</a></li>
<li class="toctree-l2"><a class="reference internal" href="numpy_extensions_tutorial.html#parametrized-example">Parametrized example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="super_resolution_with_caffe2.html">Transfering a model from PyTorch to Caffe2 and Mobile using ONNX</a><ul>
<li class="toctree-l2"><a class="reference internal" href="super_resolution_with_caffe2.html#transfering-srresnet-using-onnx">Transfering SRResNet using ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_resolution_with_caffe2.html#running-the-model-on-mobile-devices">Running the model on mobile devices</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">Custom C++ and CUDA Extensions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cpp_extension.html#motivation-and-example">Motivation and Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="cpp_extension.html#writing-a-c-extension">Writing a C++ Extension</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cpp_extension.html#building-with-setuptools">Building with <code class="docutils literal notranslate"><span class="pre">setuptools</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="cpp_extension.html#writing-the-c-op">Writing the C++ Op</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cpp_extension.html#forward-pass">Forward Pass</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpp_extension.html#backward-pass">Backward Pass</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cpp_extension.html#binding-to-python">Binding to Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpp_extension.html#using-your-extension">Using Your Extension</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cpp_extension.html#performance-comparison">Performance Comparison</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpp_extension.html#performance-on-gpu-devices">Performance on GPU Devices</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cpp_extension.html#jit-compiling-extensions">JIT Compiling Extensions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cpp_extension.html#writing-a-mixed-c-cuda-extension">Writing a Mixed C++/CUDA extension</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cpp_extension.html#integrating-a-c-cuda-operation-with-pytorch">Integrating a C++/CUDA Operation with PyTorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cpp_extension.html#id2">Performance Comparison</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cpp_extension.html#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>



        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">


      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">

          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyTorch Tutorials</a>

      </nav>



      <div class="wy-nav-content">
        <div class="rst-content">
















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">

      <li><a href="../index.html">Docs</a> &raquo;</li>

      <li>PyTorch를 이용한 신경망-변환(Neural-Transfer)</li>


      <li class="wy-breadcrumbs-aside">


            <a href="../_sources/advanced/neural_style_tutorial.rst.txt" rel="nofollow"> View page source</a>


      </li>

  </ul>


  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">

  <div class="section" id="pytorch-neural-transfer">
<span id="sphx-glr-advanced-neural-style-tutorial-py"></span><h1>PyTorch를 이용한 신경망-변환(Neural-Transfer)<a class="headerlink" href="#pytorch-neural-transfer" title="Permalink to this headline">¶</a></h1>
<dl class="docutils">
<dt><strong>저자</strong>: <a class="reference external" href="https://alexis-jacq.github.io">Alexis Jacq</a></dt>
<dd><strong>번역</strong>: <a class="reference external" href="http://fmttm.egloos.com">김봉모</a></dd>
</dl>
<div class="section" id="id2">
<h2>소개<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>환영합니다!. 이 문서는 Leon A. Gatys와 Alexander S. Ecker, Matthias Bethge 가 개발한
알고리즘인 <a class="reference external" href="https://arxiv.org/abs/1508.06576">Neural-Style</a> 를 구현하는 방법에 대해
설명하는 튜토리얼입니다.</p>
<div class="section" id="id3">
<h3>신경망 뭐라고?<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>신경망 스타일(Neural-Style), 혹은 신경망 변화(Neural-Transfer)는 콘텐츠 이미지(예, 거북이)와
스타일 이미지(예, 파도를 그린 예술 작품) 을 입력으로 받아 콘텐츠 이미지의 모양대로 스타일 이미지의
‘그리는 방식’을 이용해 그린 것처럼 결과를 내는 알고리즘입니다:</p>
<div class="figure">
<img alt="content1" src="../_images/neuralstyle.png" />
</div>
</div>
<div class="section" id="id4">
<h3>어떻게 동작합니까?<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>원리는 간단합니다. 2개의 거리(distance)를 정의합니다. 하나는 콘텐츠( <span class="math notranslate">\(D_C\)</span> )를 위한 것이고
다른 하나는 스타일( <span class="math notranslate">\(D_S\)</span> )을 위한 것입니다.
<span class="math notranslate">\(D_C\)</span> 는 콘텐츠 이미지와 스타일 이미지 간의 콘텐츠가 얼마나 차이가 있는지 측정을 합니다.
반면에, <span class="math notranslate">\(D_S\)</span> 는 콘텐츠 이미지와 스타일 이미지 간의 스타일에서 얼마나 차이가 있는지를 측정합니다.
그런 다음, 세 번째 이미지를 입력(예, 노이즈로 구성된 이미지)으로부터 콘텐츠 이미지와의 콘텐츠 거리
및 스타일 이미지와의 스타일 거리를 최소화하는 방향으로 세 번째 이미지를 변환합니다.</p>
<div class="section" id="id5">
<h4>그래서. 어떻게 동작하냐고요?<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h4>
<p>자, 더 나아가려면 수학이 필요합니다. <span class="math notranslate">\(C_{nn}\)</span> 를 사전 훈련된 깊은 합성곱 신경망
네트워크(pre-trained deep convolutional neural network)라고 하고, <span class="math notranslate">\(X\)</span> 를 어떤 이미지라고 해보겠습니다.
<span class="math notranslate">\(C_{nn}(X)\)</span> 은 입력 이미지 X를 입력으로 해서 CNN 을 통과한 네트워크(모든 레이어들의 특징 맵(feature map)을 포함하는)를 의미합니다.
<span class="math notranslate">\(F_{XL} \in C_{nn}(X)\)</span> 는 깊이 레벨 L에서의 특징 맵(feature map)을 의미하고,
모두 벡터화(vectorized)되고 연결된(concatenated) 하나의 단일 벡터입니다.
그리고, <span class="math notranslate">\(Y\)</span> 를 이미지 <span class="math notranslate">\(X\)</span> 와 크기가 같은 이미지라고 하면,
레이어 <span class="math notranslate">\(L\)</span> 에 해당하는 콘텐츠의 거리를 정의할 수 있습니다:</p>
<div class="math notranslate">
\[D_C^L(X,Y) = \|F_{XL} - F_{YL}\|^2 = \sum_i (F_{XL}(i) - F_{YL}(i))^2\]</div>
<p><span class="math notranslate">\(F_{XL}(i)\)</span> 는 <span class="math notranslate">\(F_{XL}\)</span> 의 <span class="math notranslate">\(i^{번째}\)</span> 요소(element) 입니다.
스타일에 해당하는 내용은 위 내용보다 조금 더 신경 쓸 부분이 있습니다.
<span class="math notranslate">\(F_{XL}^k\)</span> 를 레이어 <span class="math notranslate">\(L\)</span> 에서 특징 맵(feature map) <span class="math notranslate">\(K\)</span> 의 <span class="math notranslate">\(k^{번째}\)</span> 에 해당하는
벡터화된 <span class="math notranslate">\(k \leq K\)</span> 라고 해 보겠습니다.
스타일 <span class="math notranslate">\(G_{XL}\)</span> 의 <span class="math notranslate">\(X\)</span> 레이어에서 <span class="math notranslate">\(L\)</span> 은 모든 벡터화된 특징 맵(feature map) <span class="math notranslate">\(F_{XL}^k\)</span>
에서 <span class="math notranslate">\(k \leq K\)</span> 그람(Gram)으로 정의 됩니다.
다시 말하면, <span class="math notranslate">\(G_{XL}\)</span> 는 <span class="math notranslate">\(K\)</span>x<span class="math notranslate">\(K\)</span> 행렬과 요소 <span class="math notranslate">\(G_{XL}(k,l)\)</span> 의 <span class="math notranslate">\(k^{번째}\)</span> 줄과
<span class="math notranslate">\(l^{번째}\)</span> 행의 <span class="math notranslate">\(G_{XL}\)</span> 는 <span class="math notranslate">\(F_{XL}^k\)</span> 와 <span class="math notranslate">\(F_{XL}^l\)</span> 간의
벡터화 곱을 의미합니다:</p>
<div class="math notranslate">
\[G_{XL}(k,l) = \langle F_{XL}^k, F_{XL}^l\rangle = \sum_i F_{XL}^k(i) . F_{XL}^l(i)\]</div>
<p><span class="math notranslate">\(F_{XL}^k(i)\)</span> 는 <span class="math notranslate">\(F_{XL}^k\)</span> 의 <span class="math notranslate">\(i^{번째}\)</span> 요소 입니다.
우리는 <span class="math notranslate">\(G_{XL}(k,l)\)</span> 를 특징 맵(feature map) <span class="math notranslate">\(k\)</span> 와 <span class="math notranslate">\(l\)</span> 간의
상관 관계(correlation)에 대한 척도로 볼 수 있습니다.
그런 의미에서, <span class="math notranslate">\(G_{XL}\)</span> 는 특징 맵(feature map) <span class="math notranslate">\(X\)</span> 의 레이어 <span class="math notranslate">\(L\)</span> 에서의
상관 관계 행렬을 나타냅니다.
<span class="math notranslate">\(G_{XL}\)</span> 의 크기는 단지 특징 맵(feature map)의 숫자에만 의존성이 있고,
<span class="math notranslate">\(X\)</span> 의 크기에는 의존성이 없다는 것을 유의 해야 합니다.
그러면, 만약 <span class="math notranslate">\(Y\)</span> 가 다른 <em>어떤 크기의</em> 이미지라면,
우리는 다음과 같이 레이어 <span class="math notranslate">\(L\)</span> 에서 스타일의 거리를 정의 합니다.</p>
<div class="math notranslate">
\[D_S^L(X,Y) = \|G_{XL} - G_{YL}\|^2 = \sum_{k,l} (G_{XL}(k,l) - G_{YL}(k,l))^2\]</div>
<p><span class="math notranslate">\(D_C(X,C)\)</span> 의 한 번의 최소화를 위해서, 이미지 변수 <span class="math notranslate">\(X\)</span> 와 대상 콘텐츠-이미지 <span class="math notranslate">\(C\)</span> 와
<span class="math notranslate">\(D_S(X,S)\)</span> 와 <span class="math notranslate">\(X\)</span> 와 대상 스타일-이미지 <span class="math notranslate">\(S\)</span> , 둘 다 여러 레이어들에 대해서 계산되야 하고,
우리는 원하는 레이어 각각에서의 거리의 그라디언트를 계산하고 더합니다( <span class="math notranslate">\(X\)</span> 와 관련된 도함수):</p>
<div class="math notranslate">
\[\nabla_{    extit{total}}(X,S,C) = \sum_{L_C} w_{CL_C}.\nabla_{     extit{content}}^{L_C}(X,C) + \sum_{L_S} w_{SL_S}.\nabla_{       extit{style}}^{L_S}(X,S)\]</div>
<p><span class="math notranslate">\(L_C\)</span> 와 <span class="math notranslate">\(L_S\)</span> 는 각각 콘텐츠와 스타일의 원하는 (임의 상태의) 레이어들을 의미하고,
<span class="math notranslate">\(w_{CL_C}\)</span> 와 <span class="math notranslate">\(w_{SL_S}\)</span> 는 원하는 레이어에서의
스타일 또는 콘텐츠의 가중치를 (임의 상태의) 의미합니다.
그리고 나서, 우리는 <span class="math notranslate">\(X\)</span> 에 대해 경사 하강법을 실행합니다.</p>
<div class="math notranslate">
\[X \leftarrow X - \alpha \nabla_{      extit{total}}(X,S,C)\]</div>
<p>네, 수학은 이정도면 충분합니다. 만약 더 깊이 알고 싶다면 (그레이언트를 어떻게 계산하는지),
Leon A. Gatys and AL가 작성한 <strong>원래의 논문을 읽어 볼 것을 권장합니다</strong>
논문에는 앞서 설명한 내용들 모두에 대해 보다 자세하고 명확하게 얘기합니다.</p>
<p>구현을 위해서 PyTorch에서는 이미 우리가 필요로하는 모든 것을 갖추고 있습니다.
실제로 PyTorch를 사용하면 라이브러리의 함수를 사용하는 동안 모든 그라디언트(Gradient)가
자동,동적으로 계산됩니다.(라이브러리에서 함수를 사용하는 동안)
이런 점이 PyTorch에서 알고리즘 구현을 매우 편리하게 합니다.</p>
</div>
</div>
</div>
<div class="section" id="pytorch">
<h2>PyTorch 구현<a class="headerlink" href="#pytorch" title="Permalink to this headline">¶</a></h2>
<p>위의 모든 수학을 이해할 수 없다면, 구현함으로써 이해도를 높여 갈 수 있을 것 입니다.
PyTorch를 이용할 예정이라면, 먼저 이 문서 <a class="reference internal" href="../beginner/deep_learning_60min_blitz.html"><span class="doc">Introduction to PyTorch</span></a> 를 읽어볼 것을 추천 합니다.</p>
<div class="section" id="id6">
<h3>패키지들<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>우리는 다음 패키지들을 활용 할 것입니다:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">torch</span></code> , <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code>, <code class="docutils literal notranslate"><span class="pre">numpy</span></code> (PyTorch로 신경망 처리를 위한 필수 패키지)</li>
<li><code class="docutils literal notranslate"><span class="pre">torch.optim</span></code> (효율적인 그라디언트 디센트)</li>
<li><code class="docutils literal notranslate"><span class="pre">PIL</span></code> , <code class="docutils literal notranslate"><span class="pre">PIL.Image</span></code> , <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot</span></code> (이미지를 읽고 보여주는 패키지)</li>
<li><code class="docutils literal notranslate"><span class="pre">torchvision.transforms</span></code> (PIL타입의 이미지들을 토치 텐서 형태로 변형해주는 패키지)</li>
<li><code class="docutils literal notranslate"><span class="pre">torchvision.models</span></code> (사전 훈련된 모델들의 학습 또는 읽기 패키지)</li>
<li><code class="docutils literal notranslate"><span class="pre">copy</span></code> (모델들의 깊은 복사를 위한 시스템 패키지)</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="kn">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="kn">as</span> <span class="nn">models</span>

<span class="kn">import</span> <span class="nn">copy</span>
</pre></div>
</div>
</div>
<div class="section" id="cuda">
<h3>쿠다(CUDA)<a class="headerlink" href="#cuda" title="Permalink to this headline">¶</a></h3>
<p>컴퓨터에 GPU가 있는 경우, 특히 VGG와 같이 깊은 네트워크를 사용하려는 경우
알고리즘을 CUDA 환경에서 실행하는 것이 좋습니다.
CUDA를 쓰기 위해서 Pytorch에서는 <code class="docutils literal notranslate"><span class="pre">torch.cuda.is_available()</span></code> 를 제공하는데,
작업하는 컴퓨터에서 GPU 사용이 가능하면 <code class="docutils literal notranslate"><span class="pre">True</span></code> 를 리턴 합니다.
이후로, 우리는 <code class="docutils literal notranslate"><span class="pre">.cuda()</span></code> 라는 메소드를 사용하여 모듈과 관련된 할당된 프로세스를 CPU에서 GPU로 수 있습니다.
이 모듈을 CPU로 되돌리고 싶을 때에는 (예 : numpy에서 사용), 우리는 <code class="docutils literal notranslate"><span class="pre">.cpu</span> <span class="pre">()</span></code> 메소드를 사용하면 됩니다.
마지막으로, <code class="docutils literal notranslate"><span class="pre">.type(dtype)</span></code> 메소드는 <code class="docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code> 타입을
GPU에서 사용 할 수 있도록 <code class="docutils literal notranslate"><span class="pre">torch.cuda.FloatTensor</span></code> 로 변환하는데 사용할 수 있습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id7">
<h3>이미지 읽기<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>구현을 간단하게 하기 위해서, 스타일 이미지와 콘텐츠 이미지의 크기를 동일하게 맞추어서 시작합니다.
그런 다음 원하는 출력 이미지 크기로 확장 시킵니다.(본 예제에서는 128이나 512로 하는데 GPU가 가능한 상황에 맞게 선택해서 하세요.)
그리고 영상 데이터를 토치 텐서로 변환하고, 신경망 네트워크에 사용할 수 있도록 준비합니다.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">튜토리얼을 실행하는 데 필요한 이미지를 다운로드하는 링크는 다음과 같습니다.:
<a class="reference external" href="http://pytorch.org/tutorials/_static/img/neural-style/picasso.jpg">picasso.jpg</a> 와
<a class="reference external" href="http://pytorch.org/tutorials/_static/img/neural-style/dancing.jpg">dancing.jpg</a>.
위 두개의 이미지를 다운로드 받아 디렉토리 이름 <code class="docutils literal notranslate"><span class="pre">images</span></code> 에 추가하세요.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 출력 이미지의 원하는 크기를 정하세요.</span>
<span class="n">imsize</span> <span class="o">=</span> <span class="mi">512</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="mi">128</span>  <span class="c1"># gpu가 없다면 작은 크기로</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">imsize</span><span class="p">),</span>  <span class="c1"># 입력 영상 크기를 맞춤</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>  <span class="c1"># 토치 텐서로 변환</span>


<span class="k">def</span> <span class="nf">image_loader</span><span class="p">(</span><span class="n">image_name</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_name</span><span class="p">)</span>
    <span class="c1"># 네트워크의 입력 차원을 맞추기 위해 필요한 가짜 배치 차원</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">loader</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>


<span class="n">style_img</span> <span class="o">=</span> <span class="n">image_loader</span><span class="p">(</span><span class="s2">&quot;images/picasso.jpg&quot;</span><span class="p">)</span>
<span class="n">content_img</span> <span class="o">=</span> <span class="n">image_loader</span><span class="p">(</span><span class="s2">&quot;images/dancing.jpg&quot;</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">style_img</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="n">content_img</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> \
    <span class="s2">&quot;we need to import style and content images of the same size&quot;</span>
</pre></div>
</div>
<p>가져온 PIL 이미지는 0에서 255 사이의 이미지 픽셀값을 가집니다.
토치 텐서로 변환하면 0에서 1의 값으로 변환됩니다.
이는 중요한 디테일로: 토치 라이브러리의 신경망은 0에서 1의 텐서 이미지로 학습하게 됩니다.
0-255 텐서 이미지를 네트워크에 공급 하려고 하면 활성화된(activated) 특징 맵(feature map)은 의미가 없습니다.(역자주, 입력 값에 따라 RELU와 같은 활성화 레이어에서 입력으로 되는 값의 범위가 완전히 다르기 때문)
Caffe 라이브러리의 사전 훈련된 네트워크의 경우는 그렇지 않습니다: 해당 모델들은 0에서 255 사이 값의 텐서 이미지로 학습 되었습니다.</p>
</div>
<div class="section" id="id8">
<h3>이미지 표시하기<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>우리는 이미지를 표시하기 위해 <code class="docutils literal notranslate"><span class="pre">plt.imshow</span></code> 를 이용합니다.
그러기 위해 우선 텐서를 PIL 이미지로 변환해 주겠습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">unloader</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">()</span>  <span class="c1"># PIL 이미지로 재변환 합니다</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  <span class="c1"># 텐서의 값에 변화가 적용되지 않도록 텐서를 복제합니다</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>      <span class="c1"># 페이크 배치 차원을 제거 합니다</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">unloader</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> <span class="c1"># 그리는 부분이 업데이트 될 수 있게 잠시 정지합니다</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">style_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Style Image&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">content_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Content Image&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_neural_style_tutorial_001.png"><img alt="../_images/sphx_glr_neural_style_tutorial_001.png" src="../_images/sphx_glr_neural_style_tutorial_001.png" style="width: 300.79999999999995px; height: 225.6px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_neural_style_tutorial_002.png"><img alt="../_images/sphx_glr_neural_style_tutorial_002.png" src="../_images/sphx_glr_neural_style_tutorial_002.png" style="width: 300.79999999999995px; height: 225.6px;" /></a>
</li>
</ul>
</div>
<div class="section" id="id9">
<h3>콘텐츠 로스<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>콘텐츠 로스는 네트워크에서 <span class="math notranslate">\(X\)</span> 로 입력을 받았을 때 레이어 <span class="math notranslate">\(L\)</span> 에서 특징 맵(feature map) <span class="math notranslate">\(F_{XL}\)</span> 을 입력으로 가져 와서
이 이미지와 콘텐츠 이미지 사이의 가중치 콘텐츠 거리 <span class="math notranslate">\(w_{CL}.D_C^L(X,C)\)</span> 를 반환하는 기능입니다.
따라서, 가중치 <span class="math notranslate">\(w_{CL}\)</span> 및 목표 콘텐츠 <span class="math notranslate">\(F_{CL}\)</span> 은 함수의 파라미터 입니다.
우리는 이 매개 변수를 입력으로 사용하는 생성자(constructor)가 있는 토치 모듈로 함수를 구현합니다.
거리 <span class="math notranslate">\(\|F_{XL} - F_{YL}\|^2\)</span> 는 세 번째 매개 변수로 명시된 기준 <code class="docutils literal notranslate"><span class="pre">nn.MSELoss</span></code> 를 사용하여
계산할 수 있는 두 세트의 특징 맵(feature map) 사이의 평균 제곱 오차(MSE, Mean Square Error)입니다.</p>
<p>우리는 신경망의 추가 모듈로서 각 레이어에 컨텐츠 로스를 추가 할 것 입니다.
이렇게 하면 입력 영상 <span class="math notranslate">\(X\)</span> 를 네트워크에 보낼 때마다 원하는 모든 레이어에서
모든 컨텐츠 로스가 계산되고 자동 그라디언트로 인해 모든 그라디언트가 계산됩니다.
이를 위해 우리는 입력을 리턴하는 <code class="docutils literal notranslate"><span class="pre">forward</span></code> 메소드를 만들기만 하면 됩니다: 모듈은 신경망의 ‘’투명 레이어’’ 가 됩니다.
계산된 로스는 모듈의 매개 변수로 저장됩니다.</p>
<p>마지막으로 그라디언트를 재구성하기 위해 nn.MSELoss의 <code class="docutils literal notranslate"><span class="pre">backward</span></code> 메서드를 호출하는 가짜 backward 메서드를 정의 합니다.
이 메서드는 계산된 로스를 반환 합니다. 이는 스타일 및 콘텐츠 로스의 진화를 표시하기 위해 그라디언트 디센트를 실행할 때 유용합니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ContentLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ContentLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 그라디언트를 동적으로 계산하는 데 사용되는 트리에서 대상 콘텐츠를 &#39;분리&#39; 합니다.</span>
        <span class="c1"># :이 값은 변수(variable)가 아니라 명시된 값입니다.</span>
        <span class="c1"># 그렇지 않으면 기준의 전달 메소드가 오류를 발생 시킵니다.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><strong>중요한 디테일</strong>: 이 모듈은 <code class="docutils literal notranslate"><span class="pre">ContentLoss</span></code> 라고 이름 지어졌지만 진정한 PyTorch Loss 함수는 아닙니다. 컨텐츠 손실을 PyTorch Loss로 정의 하려면 PyTorch autograd Function을 생성 하고 <code class="docutils literal notranslate"><span class="pre">backward</span></code> 메소드에서 직접 그라디언트를 재계산/구현 해야 합니다.</p>
</div>
</div>
<div class="section" id="id10">
<h3>스타일 로스<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>스타일 손실을 위해 우리는 레이어 <span class="math notranslate">\(L\)</span> 에서 <span class="math notranslate">\(X\)</span> 로 공급된(입력으로 하는) 신경망의 특징 맵(feature map) <span class="math notranslate">\(F_{XL}\)</span> 이 주어진 경우
그램 생성 <span class="math notranslate">\(G_{XL}\)</span> 을 계산하는 모듈을 먼저 정의 해야 합니다.
<span class="math notranslate">\(\hat{F}_{XL}\)</span> 을 KxN 행렬에 대한 <span class="math notranslate">\(F_{XL}`의 모양을 변경한 버전이라고 하겠습니다.
여기서, :math:`K`는 레이어 :math:`L`에서의 특징 맵(feature map)들의 수이고, :math:`N\)</span> 은 임의의 벡터화 된 특징 맵(feature map) <span class="math notranslate">\(F_{XL}^k\)</span> 의 길이가 됩니다.
<span class="math notranslate">\(F_{XL}^k\)</span> 의 <span class="math notranslate">\(k^{번째}\)</span> 번째 줄은 <span class="math notranslate">\(F_{XL}^k\)</span> 입니다.
math:<cite>hat{F}_{XL} cdot hat{F}_{XL}^T = G_{XL}</cite> 인지 확인 해보길 바랍니다.
이를 확인해보면 모듈을 구현하는 것이 쉬워 집니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gram_matrix</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>  <span class="c1"># a=배치 크기(=1)</span>
    <span class="c1"># b=특징 맵의 크기</span>
    <span class="c1"># (c,d)=특징 맵(N=c*d)의 차원</span>

    <span class="n">features</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">*</span> <span class="n">d</span><span class="p">)</span>  <span class="c1"># F_XL을 \hat F_XL로 크기 조정합니다</span>

    <span class="n">G</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">features</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>  <span class="c1"># 그램 곱을 수행합니다</span>

    <span class="c1"># 그램 행렬의 값을 각 특징 맵의 요소 숫자로 나누는 방식으로 &#39;정규화&#39;를 수행합니다.</span>
    <span class="k">return</span> <span class="n">G</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span> <span class="o">*</span> <span class="n">c</span> <span class="o">*</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
<p>특징 맵(feature map) 차원 :math:<a href="#id11"><span class="problematic" id="id12">`</span></a>N`이 클수록, 그램(Gram) 행렬의 값이 커집니다.
따라서 :math:<a href="#id13"><span class="problematic" id="id14">`</span></a>N`으로 정규화하지 않으면 첫번째 레이어에서 계산된 로스 (풀링 레이어 전에)는
경사 하강법 동안 훨씬 더 중요하게 됩니다. (역자주 : 정규화를 하지 않으면 첫번째 레이어에서 계산된 값들의 가중치가 높아져 상대적으로 다른 레이어에서 계산한 값들의 반영이 적게 되버리기 때문에 정규화가 필요해집니다.)
스타일 특징의 흥미로운 부분들은 가장 깊은 레이어에 있기 때문에 그렇게 동작하지 않도록 해야 합니다!</p>
<p>그런 다음 스타일 로스 모듈은 콘텐츠 로스 모듈과 완전히 동일한 방식으로 구현되지만
대상과 입력 간의 그램 매트릭스의 차이를 비교하게 됩니다</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StyleLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_feature</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StyleLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">gram_matrix</span><span class="p">(</span><span class="n">target_feature</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">G</span> <span class="o">=</span> <span class="n">gram_matrix</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span>
</pre></div>
</div>
</div>
<div class="section" id="id15">
<h3>뉴럴 네트워크 읽기<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>자, 우리는 사전 훈련된 신경망을 가져와야 합니다. 이 논문에서와 같이,
우리는 19 레이어 층을 가지는 VGG(VGG19) 네트워크를 사전 훈련된 네트워크로 사용할 것입니다.</p>
<p>PyTorch의 VGG 구현은 두 개의 하위 순차 모듈로 나뉜 모듈 입니다.
<code class="docutils literal notranslate"><span class="pre">특징(features)</span></code> 모듈 : 합성곱과 풀링 레이어들을 포함 합니다.
<code class="docutils literal notranslate"><span class="pre">분류(classifier)</span></code> 모듈 : fully connected 레이어들을 포함 합니다.
우리는 여기서 <code class="docutils literal notranslate"><span class="pre">특징</span></code> 모듈에 관심이 있습니다.
일부 레이어는 학습 및 평가에 있어서 상황에 따라 다른 동작을 합니다.
이후 우리는 그것을 특징 추출자로 사용하고 있습니다.
우리는 .eval() 을 사용하여 네트워크를 평가 모드로 설정 할 수 있습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cnn</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg19</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<p>또한 VGG 네트워크는 평균 = [0.485, 0.456, 0.406] 및 표준편차 = [0.229, 0.224, 0.225]로 정규화 된 각 채널의 이미지에 대해 학습된 모델입니다.
(역자, 일반적으로 네트워크는 이미지넷으로 학습이 되고 이미지넷 데이터의 평균과 표준편차가 위의 값과 같습니다.)
우리는 입력 이미지를 네트워크로 보내기 전에 정규화 하는데 위 평균과 표준편차 값을 사용합니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cnn_normalization_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">cnn_normalization_std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># 입력 이미지를 정규화하는 모듈을 만들어 nn.Sequential에 쉽게 입력 할 수 있게 하세요.</span>
<span class="k">class</span> <span class="nc">Normalization</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Normalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># .view(텐서의 모양을 바꾸는 함수)로 평균과 표준 편차 텐서를 [C x 1 x 1] 형태로 만들어</span>
        <span class="c1"># 바로 입력 이미지 텐서의 모양인 [B x C x H x W] 에 연산할 수 있도록 만들어 주세요.</span>
        <span class="c1"># B는 배치 크기, C는 채널 값, H는 높이, W는 넓이 입니다.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="c1"># img 값 정규화(normalize)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">img</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">std</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">순차(Sequential)</span></code> 모듈에는 하위 모듈의 정렬된 목록이 있습니다.
예를 들어 <code class="docutils literal notranslate"><span class="pre">vgg19.features</span></code> 은 vgg19 구조의 올바른 순서로 정렬된 순서 정보(Conv2d, ReLU, MaxPool2d, Conv2d, ReLU …)를 포함합니다.
콘텐츠 로스 섹션에서 말했듯이 우리는 네트워크의 원하는 레이어에 추가 레이어 ‘투명(transparent)’레이어로 스타일 및 콘텐츠 손실 모듈을 추가하려고 합니다.
이를 위해 새로운 순차 모듈을 구성합니다.이 모듈에서는 vgg19의 모듈과 손실 모듈을 올바른 순서로 추가합니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 스타일/콘텐츠 로스로 계산하길 원하는 깊이의 레이어들:</span>
<span class="n">content_layers_default</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;conv_4&#39;</span><span class="p">]</span>
<span class="n">style_layers_default</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;conv_1&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_2&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_3&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_5&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">get_style_model_and_losses</span><span class="p">(</span><span class="n">cnn</span><span class="p">,</span> <span class="n">normalization_mean</span><span class="p">,</span> <span class="n">normalization_std</span><span class="p">,</span>
                               <span class="n">style_img</span><span class="p">,</span> <span class="n">content_img</span><span class="p">,</span>
                               <span class="n">content_layers</span><span class="o">=</span><span class="n">content_layers_default</span><span class="p">,</span>
                               <span class="n">style_layers</span><span class="o">=</span><span class="n">style_layers_default</span><span class="p">):</span>
    <span class="n">cnn</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">cnn</span><span class="p">)</span>

    <span class="c1"># 표준화(normalization) 모듈</span>
    <span class="n">normalization</span> <span class="o">=</span> <span class="n">Normalization</span><span class="p">(</span><span class="n">normalization_mean</span><span class="p">,</span> <span class="n">normalization_std</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># 단지 반복 가능한 접근을 갖거나 콘텐츠/스타일의 리스트를 갖기 위함</span>
    <span class="c1"># 로스값</span>
    <span class="n">content_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">style_losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># cnn은 nn.Sequential 하다고 가정하므로, 새로운 nn.Sequential을 만들어</span>
    <span class="c1"># 우리가 순차적으로 활성화 하고자하는 모듈들을 넣겠습니다.</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">normalization</span><span class="p">)</span>

    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># conv레이어를 찾을때마다 값을 증가 시킵니다</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">cnn</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv_{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;relu_{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="c1"># in-place(입력 값을 직접 업데이트) 버전은 콘텐츠로스와 스타일로스에</span>
            <span class="c1"># 좋은 결과를 보여주지 못합니다.</span>
            <span class="c1"># 그래서 여기선 out-of-place로 대체 하겠습니다.</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;pool_{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;bn_{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Unrecognized layer: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>

        <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">content_layers</span><span class="p">:</span>
            <span class="c1"># 콘텐츠 로스 추가:</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">content_img</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">content_loss</span> <span class="o">=</span> <span class="n">ContentLoss</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;content_loss_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">content_loss</span><span class="p">)</span>
            <span class="n">content_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">content_loss</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">style_layers</span><span class="p">:</span>
            <span class="c1"># 스타일 로스 추가:</span>
            <span class="n">target_feature</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">style_img</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">style_loss</span> <span class="o">=</span> <span class="n">StyleLoss</span><span class="p">(</span><span class="n">target_feature</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;style_loss_{}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">style_loss</span><span class="p">)</span>
            <span class="n">style_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">style_loss</span><span class="p">)</span>

    <span class="c1"># 이제 우리는 마지막 콘텐츠 및 스타일 로스 이후의 레이어들을 잘라냅니다.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ContentLoss</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">StyleLoss</span><span class="p">):</span>
            <span class="k">break</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">[:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">style_losses</span><span class="p">,</span> <span class="n">content_losses</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>논문에서는 맥스 풀링(Max Pooling) 레이어를 에버리지 풀링(Average Pooling) 레이어로 바꾸는 것을 추천합니다.
AlexNet에서는 논문에서 사용된 VGG19 네트워크보다 상대적으로 작은 네트워크라 결과 품질에서
큰 차이를 확인하기 어려울 수 있습니다.
그러나, 만약 당신이 대체해 보기를 원한다면 아래 코드들을 사용할 수 있습니다:</p>
<div class="last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># avgpool = nn.AvgPool2d(kernel_size=layer.kernel_size,</span>
<span class="c1">#                         stride=layer.stride, padding = layer.padding)</span>
<span class="c1"># model.add_module(name,avgpool)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id16">
<h3>입력 이미지<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<p>다시, 코드를 간단하게 하기 위해, 콘텐츠와 스타일 이미지들의 같은 차원의 이미지를 가져옵니다.
해당 이미지는 백색 노이즈일 수 있거나 콘텐츠-이미지의 값들을 복사해도 좋습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">input_img</span> <span class="o">=</span> <span class="n">content_img</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="c1"># 대신에 백색 노이즈를 이용하길 원한다면 아래 줄의 주석처리를 제거하세요:</span>
<span class="c1"># input_img = torch.randn(content_img.data.size(), device=device)</span>

<span class="c1"># 원본 입력 이미지를 창에 추가합니다:</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">input_img</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Input Image&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_neural_style_tutorial_003.png" class="align-center" src="../_images/sphx_glr_neural_style_tutorial_003.png" />
</div>
<div class="section" id="id17">
<h3>경사 하강법<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<p>알고리즘의 저자인 Len Gatys 가 <a class="reference external" href="https://discuss.pytorch.org/t/pytorch-tutorial-for-neural-transfert-of-artistic-style/336/20?u=alexis-jacq">여기서</a> 제안한 방식대로
경사 하강법을 실행하는데 L-BFGS 알고리즘을 사용 하겠습니다.
일반적인 네트워크 학습과는 다르게, 우리는 콘텐츠/스타일 로스를 최소화 하는 방향으로 입력 영상을 학습 시키려고 합니다.
우리는 간단히 PyTorch L-BFGS 옵티마이저 <code class="docutils literal notranslate"><span class="pre">optim.LBFGS</span></code> 를 생성하려고 하며, 최적화를 위해 입력 이미지를 텐서 타입으로 전달합니다.
우리는 <code class="docutils literal notranslate"><span class="pre">.requires_grad_()</span></code> 를 사용하여 해당 이미지가 그라디언트가 필요함을 확실하게 합니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_input_optimizer</span><span class="p">(</span><span class="n">input_img</span><span class="p">):</span>
    <span class="c1"># 이 줄은 입력은 그레이던트가 필요한 파라미터라는 것을 보여주기 위해 있습니다.</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">([</span><span class="n">input_img</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()])</span>
    <span class="k">return</span> <span class="n">optimizer</span>
</pre></div>
</div>
<p><strong>마지막 단계</strong>: 경사 하강의 반복. 각 단계에서 우리는 네트워크의 새로운 로스를 계산하기 위해
업데이트 된 입력을 네트워크에 공급해야 합니다. 우리는 그라디언트를 동적으로 계산하고
그라디언트 디센트의 단계를 수행하기 위해 각 손실의 <code class="docutils literal notranslate"><span class="pre">역방향(backward)</span></code> 메소드를 실행해야 합니다.
옵티마이저는 인수로서 “클로저(closure)”를 필요로 합니다: 즉, 모델을 재평가하고 로스를 반환 하는 함수입니다.</p>
<p>그러나, 여기에 작은 함정이 있습니다. 최적화 된 이미지는 0 과 1 사이에 머물지 않고 <span class="math notranslate">\(-\infty`과 :math:`+\infty\)</span> 사이의 값을 가질 수 있습니다.
다르게 말하면, 이미지는 잘 최적화될 수 있고(0-1 사이의 정해진 값 범위내의 값을 가질 수 있고) 이상한 값을 가질 수도 있습니다.
사실 우리는 입력 이미지가 올바른 범위의 값을 유지할 수 있도록 제약 조건 하에서 최적화를 수행해야 합니다.
각 단계마다 0-1 간격으로 값을 유지하기 위해 이미지를 수정하는 간단한 해결책이 있습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_style_transfer</span><span class="p">(</span><span class="n">cnn</span><span class="p">,</span> <span class="n">normalization_mean</span><span class="p">,</span> <span class="n">normalization_std</span><span class="p">,</span>
                       <span class="n">content_img</span><span class="p">,</span> <span class="n">style_img</span><span class="p">,</span> <span class="n">input_img</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                       <span class="n">style_weight</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">content_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;스타일 변환을 실행합니다.&quot;&quot;&quot;</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Building the style transfer model..&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">style_losses</span><span class="p">,</span> <span class="n">content_losses</span> <span class="o">=</span> <span class="n">get_style_model_and_losses</span><span class="p">(</span><span class="n">cnn</span><span class="p">,</span>
        <span class="n">normalization_mean</span><span class="p">,</span> <span class="n">normalization_std</span><span class="p">,</span> <span class="n">style_img</span><span class="p">,</span> <span class="n">content_img</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">get_input_optimizer</span><span class="p">(</span><span class="n">input_img</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Optimizing..&#39;</span><span class="p">)</span>
    <span class="n">run</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">while</span> <span class="n">run</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">num_steps</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
            <span class="c1"># 입력 이미지의 업데이트된 값들을 보정합니다</span>
            <span class="n">input_img</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">model</span><span class="p">(</span><span class="n">input_img</span><span class="p">)</span>
            <span class="n">style_score</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">content_score</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">sl</span> <span class="ow">in</span> <span class="n">style_losses</span><span class="p">:</span>
                <span class="n">style_score</span> <span class="o">+=</span> <span class="n">sl</span><span class="o">.</span><span class="n">loss</span>
            <span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="n">content_losses</span><span class="p">:</span>
                <span class="n">content_score</span> <span class="o">+=</span> <span class="n">cl</span><span class="o">.</span><span class="n">loss</span>

            <span class="n">style_score</span> <span class="o">*=</span> <span class="n">style_weight</span>
            <span class="n">content_score</span> <span class="o">*=</span> <span class="n">content_weight</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">style_score</span> <span class="o">+</span> <span class="n">content_score</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">run</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">run</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s2">&quot;run {}:&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">run</span><span class="p">))</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Style Loss : {:4f} Content Loss: {:4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">style_score</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">content_score</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
                <span class="k">print</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">style_score</span> <span class="o">+</span> <span class="n">content_score</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>

    <span class="c1"># 마지막 보정...</span>
    <span class="n">input_img</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">input_img</span>
</pre></div>
</div>
<p>마지막으로, 알고리즘을 실행 시킵니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">run_style_transfer</span><span class="p">(</span><span class="n">cnn</span><span class="p">,</span> <span class="n">cnn_normalization_mean</span><span class="p">,</span> <span class="n">cnn_normalization_std</span><span class="p">,</span>
                            <span class="n">content_img</span><span class="p">,</span> <span class="n">style_img</span><span class="p">,</span> <span class="n">input_img</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Output Image&#39;</span><span class="p">)</span>

<span class="c1"># sphinx_gallery_thumbnail_number = 4</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_neural_style_tutorial_004.png" class="align-center" src="../_images/sphx_glr_neural_style_tutorial_004.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Building</span> <span class="n">the</span> <span class="n">style</span> <span class="n">transfer</span> <span class="n">model</span><span class="o">..</span>
<span class="n">Optimizing</span><span class="o">..</span>
<span class="n">run</span> <span class="p">[</span><span class="mi">50</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">4.125270</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">4.188891</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">100</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">1.140037</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">3.030362</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">150</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.709859</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.655770</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">200</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.478313</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.500814</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">250</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.350412</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.411426</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">300</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.266629</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">2.359128</span>
</pre></div>
</div>
<p><strong>Total running time of the script:</strong> ( 0 minutes  29.863 seconds)</p>
<div class="sphx-glr-footer docutils container">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/neural_style_tutorial.py" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">neural_style_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/neural_style_tutorial.ipynb" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">neural_style_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


           </div>
           <div class="articleComments">

           </div>
          </div>
          <footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">

        <a href="numpy_extensions_tutorial.html" class="btn btn-neutral float-right" title="Creating extensions using numpy and scipy" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>


        <a href="../intermediate/spatial_transformer_tutorial.html" class="btn btn-neutral" title="공간 변형기 네트워크(Spatial Transformer Networks) 튜토리얼" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>

    </div>


  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, PyTorch.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.

</footer>

        </div>
      </div>

    </section>

  </div>





    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.4.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>





    <script type="text/javascript" src="../_static/js/theme.js"></script>




  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-71919972-3', 'auto');
  ga('send', 'pageview');

</script>


</body>
</html>